{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training GMM Model from PKL files\n",
    "## GMM - CQCC\n",
    "## GMM - MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T14:40:28.189816Z",
     "start_time": "2021-04-18T14:40:28.184477Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture as GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T14:40:28.556168Z",
     "start_time": "2021-04-18T14:40:28.549248Z"
    }
   },
   "outputs": [],
   "source": [
    "root_path = 'Users/asimadnan/Desktop/Mres/ASVSPOOF_DATA/LA/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T14:51:15.830222Z",
     "start_time": "2021-04-18T14:51:15.825249Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features_path = '/Users/asimadnan/Desktop/Mres/Experiments/testfiles/la_train_mfcc_cqcc.pkl'\n",
    "dev_features_path = '/Users/asimadnan/Desktop/Mres/Experiments/testfiles/la_dev_mfcc_cqcc.pkl'\n",
    "output_path = '/Users/asimadnan/Desktop/Mres/ASVSPOOF_DATA/LA/output_data/'\n",
    "\n",
    "# sample small file to test evrything, comment this line after all tests run correctly\n",
    "train_features_path = '/Users/asimadnan/Desktop/Mres/Experiments/testfiles/04-04-2021_15-09_dev_1.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T15:00:47.120137Z",
     "start_time": "2021-04-18T15:00:47.108214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "with open(train_features_path, 'rb') as infile:\n",
    "        i=0\n",
    "        data = pickle.load(infile)\n",
    "        total_files = len(data)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T14:40:46.373438Z",
     "start_time": "2021-04-18T14:40:46.367818Z"
    }
   },
   "source": [
    "### Extract CQCC from train & dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T14:45:09.753646Z",
     "start_time": "2021-04-18T14:45:09.738894Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_feature(pkl_path,feature_type):\n",
    "    max_len = 50  # 1.25 seconds  # check the timesteps of cqcc and mfcc \n",
    "    X = []\n",
    "    y = []\n",
    "    i=0\n",
    "    with open(pkl_path, 'rb') as infile:\n",
    "        data = pickle.load(infile)\n",
    "        total_files = len(data)\n",
    "        for feat_cqcc, feat_mfcc, label,filename in data:\n",
    "\n",
    "            features = []\n",
    "            feature_block = ''\n",
    "           \n",
    "            if feature_type == 'mfcc':\n",
    "                feature_block = feat_mfcc\n",
    "            elif feature_type == 'cqcc':\n",
    "                \n",
    "                feature_block = feat_cqcc\n",
    "\n",
    "\n",
    "            if len(feature_block) > max_len:\n",
    "                features = feature_block[:max_len]\n",
    "            elif len(feature_block) < max_len:\n",
    "                features = np.concatenate((feature_block, np.array([[0.]*num_dim]*(max_len-len(feature_block)))), axis=0)\n",
    "            \n",
    "            if (i%100 == 0):\n",
    "                print( ((i/total_files)*100), ' % done' )\n",
    "            i+=1\n",
    "            X.append(features.reshape(-1))\n",
    "            y.append([label,filename])\n",
    "        return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T14:54:44.557752Z",
     "start_time": "2021-04-18T14:54:44.487222Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change this acordingly, these are used to set the file name\n",
    "feature = 'cqcc'\n",
    "dataset = 'train'\n",
    "###\n",
    "\n",
    "X,y = extract_feature(train_features_path,feature)\n",
    "train_cqcc = np.append(np.array(X),np.array(y),1)\n",
    "pd.DataFrame(train_cqcc).to_csv(os.path.join(output_path + dataset + '_' + feature + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this acordingly, these are used to set the file name\n",
    "feature = 'mfcc'\n",
    "dataset = 'train'\n",
    "###\n",
    "\n",
    "X,y = extract_feature(train_features_path,feature)\n",
    "train_cqcc = np.append(np.array(X),np.array(y),1)\n",
    "pd.DataFrame(train_cqcc).to_csv(os.path.join(output_path + dataset + '_' + feature + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this acordingly, these are used to set the file name\n",
    "feature = 'cqcc'\n",
    "dataset = 'dev'\n",
    "###\n",
    "\n",
    "X,y = extract_feature(train_features_path,feature)\n",
    "train_cqcc = np.append(np.array(X),np.array(y),1)\n",
    "pd.DataFrame(train_cqcc).to_csv(os.path.join(output_path + dataset + '_' + feature + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this acordingly, these are used to set the file name\n",
    "feature = 'cqcc'\n",
    "dataset = 'dev'\n",
    "###\n",
    "\n",
    "X,y = extract_feature(train_features_path,feature)\n",
    "train_cqcc = np.append(np.array(X),np.array(y),1)\n",
    "pd.DataFrame(train_cqcc).to_csv(os.path.join(output_path + dataset + '_' + feature + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-18T14:56:08.515016Z",
     "start_time": "2021-04-18T14:56:08.314592Z"
    }
   },
   "outputs": [],
   "source": [
    "############ \n",
    "#testing if created file is in correct format\n",
    "abc = pd.read_csv(output_path + dataset + '_' + feature + '.csv',index_col=0)\n",
    "########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
